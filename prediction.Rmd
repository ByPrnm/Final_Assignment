---
title: "Predicting Exercise Activity Type with Random Forest"
author: "Bayu Purnomo"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction
The goal of this project is to predict the manner in which individuals performed barbell lifts using sensor data. The target variable is classe, which represents the correct classification of the activity. The dataset provided includes time-series data from accelerometers on the belt, forearm, arm, and dumbbell. This project follows a structured machine learning workflow including data cleaning, feature selection, model training using Random Forest, cross-validation, model evaluation, and prediction on a final test set.

## Load Required Libraries and Data
```{r load_libraries_data}
library(caret)
library(randomForest)
library(ggplot2)
library(dplyr)

# Read the data
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
```

## Data Preprocessing
- Remove columns with mostly NA values
- Remove near-zero variance predictors
- Remove identifier and timestamp columns

```{r preprocessing}
# Remove columns with >95% NA values
na_cols <- colMeans(is.na(training)) > 0.95
training <- training[, !na_cols]
testing <- testing[, !na_cols]

# Remove near-zero variance predictors
nzv <- nearZeroVar(training)
training <- training[, -nzv]
testing <- testing[, -nzv]

# Remove ID and timestamp columns (first 7 columns)
training <- training[, -(1:7)]
testing <- testing[, -(1:7)]

# Split into training and validation sets
set.seed(12345)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
train_data <- training[inTrain, ]
validation_data <- training[-inTrain, ]
```

## Model Training with Random Forest and Cross-Validation
We use 5-fold cross-validation to train the model and avoid overfitting.

```{r model_training}
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(classe ~ ., data = train_data, method = "rf",
                 trControl = ctrl, ntree = 500)
```

## Model Evaluation
Evaluate the model on the validation set using a confusion matrix and calculate the expected out-of-sample error.

```{r model_evaluation}
val_pred <- predict(rf_model, validation_data)
confusion_matrix <- confusionMatrix(val_pred, factor(validation_data$classe))

# Show results
confusion_matrix

# Calculate out-of-sample error
oos_error <- 1 - confusion_matrix$overall["Accuracy"]
paste("Out of Sample Error Rate:", round(oos_error * 100, 2), "%")
```

## Feature Importance
Explore and visualize the top 20 most important features according to the model.

```{r feature_importance}
importance <- varImp(rf_model)
print("Top 10 Most Important Features:")
importance$importance[1:10, ]

plot(importance, top = 20, main = "Top 20 Important Features")
```

## Predictions on Test Set
Make predictions on the 20 final test cases and save them to a CSV file.

```{r predictions}
test_pred <- predict(rf_model, testing)

# Show predictions
test_pred

# Save to file
predictions <- data.frame(problem_id = testing$problem_id, predicted = test_pred)
write.csv(predictions, "predictions.csv", row.names = FALSE)
```

## Conclusion
This project successfully built a predictive model to classify the type of exercise performed using sensor data. The Random Forest algorithm, with proper preprocessing and cross-validation, achieved excellent accuracy and low expected error.

### Summary of Key Steps:
- Cleaned data by removing irrelevant and sparse columns
- Applied Random Forest with 5-fold cross-validation
- Achieved ~99% accuracy on validation set
- Identified key features affecting predictions
- Predicted on 20 test cases for submission
