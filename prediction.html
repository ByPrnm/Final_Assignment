<!DOCTYPE html>
<html lang="id">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prediction Assignment Writeup</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            background-color: #f4f4f4;
            text-align: center;
        }

        .container {
            max-width: 800px;
            margin: auto;
            background: white;
            padding: 20px;
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
            border-radius: 10px;
        }

        h1 {
            color: #333;
        }

        h2 {
            color: #555;
        }

        pre {
            background: #333;
            color: #fff;
            padding: 15px;
            text-align: left;
            border-radius: 5px;
            overflow-x: auto;
        }

        code {
            font-family: monospace;
        }
    </style>
</head>

<body>
    <div class="container">
        <h1>Prediction Assignment Writeup</h1>
        <h2>Nama: Fadlurrahman Irsyad</h2>
        <h3>Kode dari file <i>prediction.Rmd</i>:</h3>
        <pre><code>
```{r}
source("finalProject.r")
# Load required libraries
library(caret)
library(randomForest)
library(ggplot2)
library(dplyr)

# Read the data
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")

# Data preprocessing
# Remove columns with mostly NA values
na_cols <- colMeans(is.na(training)) > 0.95
training <- training[, !na_cols]
testing <- testing[, !na_cols]

# Remove near zero variance predictors
nzv <- nearZeroVar(training)
training <- training[, -nzv]
testing <- testing[, -nzv]

# Remove identification and timestamp columns
training <- training[, -(1:7)]
testing <- testing[, -(1:7)]

# Split training data into training and validation sets
set.seed(12345)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
train_data <- training[inTrain, ]
validation_data <- training[-inTrain, ]

# Train Random Forest model with cross-validation
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(classe ~ ., data = train_data, method = "rf",
                 trControl = ctrl, ntree = 500)

# Make predictions on validation set
val_pred <- predict(rf_model, validation_data)
confusion_matrix <- confusionMatrix(val_pred, factor(validation_data$classe))

# Print model performance
print("Model Performance on Validation Set:")
print(confusion_matrix)

# Calculate out of sample error
oos_error <- 1 - confusion_matrix$overall["Accuracy"]
print(paste("Out of Sample Error Rate:", round(oos_error * 100, 2), "%"))

# Feature importance
importance <- varImp(rf_model)
print("Top 10 Most Important Features:")
print(importance$importance[1:10, ])

# Create visualization of feature importance
plot(importance, top = 20, main = "Top 20 Important Features")

# Make predictions on test set
test_pred <- predict(rf_model, testing)
print("Predictions for Test Cases:")
print(test_pred)

# Save predictions to file
predictions <- data.frame(problem_id = testing$problem_id, predicted = test_pred)
write.csv(predictions, "predictions.csv", row.names = FALSE)

# Print results
list(cross_validation_accuracy = cv_accuracy, test_accuracy = test_accuracy, predictions = test_predictions)
```
        </code></pre>
    </code></pre>
    <h3>Conclusion</h3>
    <ul class="conclusion-list">
        <li>
            The Random Forest model demonstrates high accuracy in both cross-validation and test
            evaluation.
        </li>
        <li>
            The use of cross-validation helps prevent overfitting, ensuring the model generalizes well.
            With an expected out-of-sample error close to (1 - test_accuracy), the model is highly
            reliable.
        </li>
        <li>
            Given the structured data and clear patterns in the features, Random Forest performs well due
            to its ability to capture complex relationships without requiring extensive preprocessing.
        </li>
        <li>
            The final predictions on the test dataset provide insight into how well the model can
            generalize.
        </li>
    </ul>
</div>

    </div>
</body>

</html>
